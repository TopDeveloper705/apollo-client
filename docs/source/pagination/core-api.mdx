---
title: Core pagination API
sidebar_title: Core API
description: Fetching and caching paginated results
---

The Apollo Client APIs described in this article are useful for handling all paginated list fields, regardless of which pagination strategy a field uses.

## The `fetchMore` function

Pagination always involves sending followup queries to your GraphQL server to obtain additional pages of results. In Apollo Client, the recommended way to send these followup queries is with the [`fetchMore`](../caching/advanced-topics/#incremental-loading-fetchmore) function. This function is a member of the `ObservableQuery` object returned by `client.watchQuery`, and it's also included in the object returned by the `useQuery` hook:

```js
const { loading, data, fetchMore } = useQuery(GET_ITEMS, { //highlight-line
  variables: {
    offset: 0,
    limit: 10
  },
});
```

When you then call `fetchMore`, you can provide a new set of `variables` in the function's `options` object (such as a new `offset`):

```js
fetchMore({
  variables: {
    offset: 10,
    limit: 10
  },
});
```

You can also optionally provide an entirely different shape of `query` to execute (by default, the original query's shape is used).

> In Apollo Client 2, you would also provide `fetchMore` an `updateQuery` function, which was responsible for merging the followup query's results with your existing cached data. In Apollo Client 3, you instead [define custom `merge` functions](#merging-paginated-results). This enables you to specify all of your pagination logic in a central location, instead of duplicating it everywhere you call `fetchMore`.

Full examples of using `fetchMore` are provided in the detailed documentation for [offset-based pagination](./offset-based) and [cursor-based pagination](./cursor-based). The rest of this article covers the field policy configuration API that enables `fetchMore` to ignore how followup query results are cached.

## Merging paginated results

> The example below uses offset-based pagination, but this article applies to all pagination strategies.

To specify which page of a list field you want to fetch, you usually set the value of an argument for that field, such as `offset` or `cursor`. This argument's value is different for each query that fetches a different page of the list.

Because the argument values for these queries are different, Apollo Client treats the _results_ of the queries as different (by default). The result of each query is stored as an entirely separate entity in the cache, and each entity includes the argument values in its unique identifier.

Although this argument-based separation is helpful in most cases, it usually _isn't_ what you want when implementing pagination. Instead, you want all returned pages to be merged into a _single_ list in your cache. To achieve this, you can configure a **field policy** for the paginated field.

### Defining a field policy

A field policy specifies how a particular field in your Apollo Client cache is read and written. You can define a field policy to merge the results of paginated queries into a single list.

#### Example

Here's the server-side schema for a message feed application that uses offset-based pagination:

```graphql{2}
type Query {
  feed(offset: Int, limit: Int): [FeedItem!]
}

type FeedItem {
  id: String!
  message: String!
}
```

In our client, we want to define a field policy for `Query.feed` so that all returned pages of the list are merged into a _single_ list in our cache.

We define our field policy within the `typePolicies` option we provide the constructor of `InMemoryCache`:

```js{5-15}
const cache = new InMemoryCache({
  typePolicies: {
    Query: {
      fields: {
        feed: {
          // Don't cache separate results based on 
          // any of this field's argument values.
          keyArgs: [],

          // Combine the incoming list items with the
          // existing list items.
          merge(existing = [], incoming) {
            return [...existing, ...incoming];
          },
        }
      }
    }
  }
})
```

This field policy defines a list of **`keyArgs`**, along with a **`merge` function**. Both of these are necessary for handling pagination:

* `keyArgs` lists each argument that causes the cache to store a _separate_ result based on that argument's value. In this case, the cache shouldn't store a separate result based on either `offset` _or_ `limit`, so the list is empty.
  * Whenever a particular argument's value could cause items from an _entirely different list_ to be returned for the field, that argument _should_ be included in `keyArgs`.
  * For more information, see [Specifying key arguments](../caching/cache-field-behavior/#specifying-key-arguments).
* A `merge` function tells the Apollo Client cache how to combine `incoming` data with `existing` cached data for a particular field. Without this function, a followup query _overwrites_ the existing cached value by default.
  * For more information, see [The `merge` function](../caching/cache-field-behavior/#the-merge-function).

With this field policy in place, Apollo Client merges the results of all queries that use the following structure, regardless of argument values:

```ts
// Client-side query definition
const FEED_QUERY = gql`
  query Feed($offset: Int, $limit: Int) {
    feed(offset: $offset, limit: $limit) {
      id
      message
    }
  }
`;
```

### Designing the `merge` function

In [the example above](#example), our `merge` function is a single line:

```js
merge(existing = [], incoming) {
  return [...existing, ...incoming];
}
```

This function makes risky assumptions about the order in which the client requests pages, because it ignores the values of `offset` and `limit`. A more robust `merge` function can use `options.args` to decide where to put `incoming` data relative to `existing` data, like so:

```js
const cache = new InMemoryCache({
  typePolicies: {
    Query: {
      fields: {
        feed: {
          keyArgs: [],
          merge(existing, incoming, { args: { offset = 0 }}) {
            // Slicing is necessary because the existing data is
            // immutable, and frozen in development.
            const merged = existing ? existing.slice(0) : [];
            for (let i = 0; i < incoming.length; ++i) {
              merged[offset + i] = incoming[i];
            }
            return merged;
          },
        },
      },
    },
  },
});
```

This logic handles sequential page writes the same way the single-line strategy does, but it can also tolerate repeated, overlapping, or out-of-order writes, without duplicating any list items.

## `read` functions for paginated fields

As shown above, a `merge` function helps you combine paginated query results from your GraphQL server into a single list in your client cache. But what if you also want to configure how that locally cached list is _read_? For that, you can define a **`read` function**.

You define a `read` function for a field within its [field policy](#defining-a-field-policy), alongside the `merge` function and `keyArgs` list.  If you define a `read` function for a field, the cache calls that function whenever you query for the field. In the query response, the field is populated with the read function's return value, _instead of the field's cached value_.

> If a field policy includes both a `merge` function and a `read` function, the default value of `keyArgs` becomes `false` (i.e., _no_ arguments are key arguments). If either function _isn't_ defined, _all_ of the field's arguments are considered key arguments by default. In either case, you can define `keyArgs` yourself to override the default value.

The `read` function for a paginated field uses one of the following approaches:

* [Client-side pagination](#paginated-read-function), in which the cached list is paginated similar to the server-side list
* [_No_ pagination](#non-paginated-read-function), in which the full cached list is always returned

Although the "right" approach varies from field to field, a [non-paginated `read` function](#non-paginated-read-function) often works best for infinitely scrolling feeds. It gives your application code full control over which elements to display at a given time, without requiring any additional cache reads.

### Paginated `read` function

The `read` function for a list field can perform client-side pagination for that list. It can even transform a page before returning it, such as by sorting or filtering its elements.

This capability goes beyond returning the same pages that you fetched from your server, because a `read` function for `offset`/`limit` pagination could read from any available `offset`, with any desired `limit`:

```js
const cache = new InMemoryCache({
  typePolicies: {
    Query: {
      fields: {
        feed: {
          read(existing, { args: { offset, limit }}) {
            // A read function should always return undefined if existing is 
            // undefined. Returning undefined signals that the field is
            // missing from the cache, which instructs Apollo Client to
            // fetch its value from your GraphQL server.
            return existing && existing.slice(offset, offset + limit);
          },

          // The keyArgs list and merge function are the same as above.
          keyArgs: [],
          merge(existing, incoming, { args: { offset = 0 }}) {
            const merged = existing ? existing.slice(0) : [];
            for (let i = 0; i < incoming.length; ++i) {
              merged[offset + i] = incoming[i];
            }
            return merged;
          },
        },
      },
    },
  },
});
```

Depending on the assumptions you feel comfortable making, you might want to make this code more defensive. For example, you can provide default values for `offset` and `limit`, in case someone fetches `Query.feed` without providing arguments:

```js
const cache = new InMemoryCache({
  typePolicies: {
    Query: {
      fields: {
        feed: {
          read(existing, {
            args: {
              // Default to returning the entire cached list, if the offset and
              // limit arguments are not provided.
              offset = 0,
              limit = existing?.length,
            } = {},
          }) {
            return existing && existing.slice(offset, offset + limit);
          },
          // ... keyArgs, merge ...
        },
      },
    },
  },
});
```

This style of `read` function takes responsibility for re-paginating your data based on field arguments, essentially inverting the behavior of your `merge` function. This way, your application can query different pages using different arguments.

### Non-paginated `read` function

The `read` function for a paginated field can choose to _ignore_ arguments like `offset` and `limit`, and always return the entire list as it exists in the cache. In this case, your application code takes responsibility for slicing the list into pages depending on your needs.

If you adopt this approach, you might not need to define a `read` function at all, because you can return the cached list directly. That's why the [`offsetLimitPagination` helper function](./offset-based/#the-offsetlimitpagination-helper) is implemented _without_ a `read` function.
